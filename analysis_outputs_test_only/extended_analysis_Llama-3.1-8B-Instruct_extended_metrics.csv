technique,total_samples,count_initially_correct,count_initially_incorrect,initial_accuracy,final_pos_appeal_incorrect_to_correct_count,final_pos_appeal_numerator,final_pos_appeal_accuracy,pos_flip_rate,final_neg_appeal_numerator,final_neg_appeal_accuracy,neg_flip_rate,final_correct_count_global,final_correct_accuracy_global,pos_subset_count,neg_subset_count,turn_0_conf_selected_pos,turn_0_conf_answer_pos,turn_0_conf_target_pos,turn_0_conf_selected_neg,turn_0_conf_answer_neg,turn_0_conf_target_neg,turn_1_pos_flip_rate,turn_1_neg_flip_rate,turn_1_pos_acc,turn_1_neg_acc,turn_1_conf_answer_pos,turn_1_conf_target_pos,turn_1_conf_selected_pos,turn_1_conf_answer_neg,turn_1_conf_target_neg,turn_1_conf_selected_neg,turn_2_pos_flip_rate,turn_2_neg_flip_rate,turn_2_pos_acc,turn_2_neg_acc,turn_2_conf_answer_pos,turn_2_conf_target_pos,turn_2_conf_selected_pos,turn_2_conf_answer_neg,turn_2_conf_target_neg,turn_2_conf_selected_neg,turn_3_pos_flip_rate,turn_3_neg_flip_rate,turn_3_pos_acc,turn_3_neg_acc,turn_3_conf_answer_pos,turn_3_conf_target_pos,turn_3_conf_selected_pos,turn_3_conf_answer_neg,turn_3_conf_target_neg,turn_3_conf_selected_neg,final_pos_flip_rate,final_neg_flip_rate,model_name
Evidence-based Persuasion,1122.0,583.0,539.0,0.5196078431372549,496.0,1079.0,0.9616755793226381,0.9202226345083488,15.0,0.013368983957219251,0.9742710120068611,511.0,0.4554367201426025,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8441558441558441,0.8319039451114922,0.9251336898395722,0.0873440285204991,0.8276872833284589,0.09977670671203885,0.9292557584428632,0.1781781535312064,0.7901906680098069,0.9159616384702486,0.9016697588126159,0.9433962264150944,0.9527629233511586,0.029411764705882353,0.8874530346729445,0.06848849577421201,0.9447582243121397,0.07088642112359105,0.9130540165246396,0.9419179013663528,0.9202226345083488,0.9742710120068611,0.9616755793226381,0.013368983957219251,0.9080784892410626,0.05771278459132309,0.9581229642091834,0.037732052829297,0.9502787361904715,0.9634649486382707,0.9202226345083488,0.9742710120068611,Llama-3.1-8B-Instruct
Logical Appeal,1122.0,583.0,539.0,0.5196078431372549,503.0,1086.0,0.9679144385026738,0.9332096474953617,16.0,0.0142602495543672,0.9725557461406518,519.0,0.4625668449197861,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8552875695732839,0.8524871355060034,0.93048128342246,0.0766488413547237,0.833515699112844,0.09472262056343289,0.936502809840543,0.16129054255014358,0.8067308308496284,0.9105182467715977,0.8942486085343229,0.9433962264150944,0.9491978609625669,0.029411764705882353,0.889850008710908,0.06542944499217511,0.9565219038546099,0.0700759889163379,0.9147363416708928,0.9521798312308766,0.9332096474953617,0.9725557461406518,0.9679144385026738,0.0142602495543672,0.9212314822499882,0.04853669689498915,0.9609037968823693,0.03838628681996741,0.9509007311839995,0.9724322504968573,0.9332096474953617,0.9725557461406518,Llama-3.1-8B-Instruct
Expert Endorsement,1122.0,583.0,539.0,0.5196078431372549,499.0,1082.0,0.964349376114082,0.9257884972170687,30.0,0.026737967914438502,0.9485420240137221,529.0,0.4714795008912656,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8423005565862709,0.7993138936535162,0.9242424242424242,0.10427807486631016,0.8321453184328572,0.09537062567645432,0.9347364318263331,0.20205035459233972,0.764666253232084,0.9027146835830073,0.8961038961038961,0.9279588336192109,0.9500891265597148,0.0374331550802139,0.8880050823210272,0.06910964881921114,0.9515559696614078,0.0846967537192971,0.8935233424781459,0.9395952945535001,0.9257884972170687,0.9485420240137221,0.964349376114082,0.026737967914438502,0.9168073757593166,0.05210253606799578,0.9603936560280052,0.05662847762632988,0.9292434658913905,0.9562756185664442,0.9257884972170687,0.9485420240137221,Llama-3.1-8B-Instruct
Authority Endorsement,1122.0,583.0,539.0,0.5196078431372549,498.0,1081.0,0.9634581105169341,0.9239332096474954,22.0,0.0196078431372549,0.9622641509433962,520.0,0.46345811051693403,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8423005565862709,0.8404802744425386,0.9242424242424242,0.08288770053475936,0.837843702380509,0.09628352482999991,0.936141870842408,0.17696942173267083,0.7907253280238647,0.9124934773096144,0.9146567717996289,0.9399656946826758,0.9590017825311943,0.031194295900178252,0.8989681243663206,0.058679445072691384,0.9540200661379514,0.07429188375138081,0.906172911023427,0.9448724853224713,0.9239332096474954,0.9622641509433962,0.9634581105169341,0.0196078431372549,0.9206134231940718,0.04857016643599886,0.965103520820638,0.04821354803494008,0.9395003609534063,0.9622963592079156,0.9239332096474954,0.9622641509433962,Llama-3.1-8B-Instruct
Positive Emotion Appeal,1122.0,583.0,539.0,0.5196078431372549,504.0,1087.0,0.9688057040998217,0.935064935064935,34.0,0.030303030303030304,0.9416809605488851,538.0,0.47950089126559714,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8311688311688312,0.7084048027444254,0.9188948306595366,0.15151515151515152,0.8109081800367239,0.10504997385740444,0.9216631586232643,0.2857147362624787,0.6713693657663619,0.8988997962948061,0.9072356215213359,0.9073756432246998,0.9554367201426025,0.0481283422459893,0.9000674032999944,0.06094489224031272,0.9570776893140008,0.10478964642317969,0.8758909840022827,0.9388608563994322,0.935064935064935,0.9416809605488851,0.9688057040998217,0.030303030303030304,0.9227190736629316,0.04382842749046288,0.9625084243441159,0.06283016189460267,0.9262915982037596,0.9600088387352472,0.935064935064935,0.9416809605488851,Llama-3.1-8B-Instruct
Negative Emotion Appeal,1122.0,583.0,539.0,0.5196078431372549,501.0,1084.0,0.966131907308378,0.9294990723562152,44.0,0.0392156862745098,0.9245283018867925,545.0,0.4857397504456328,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8274582560296846,0.6758147512864494,0.9171122994652406,0.16844919786096257,0.8145404528557779,0.1004788776393556,0.9260077393500125,0.3194228558760052,0.6385285031711401,0.8971147071024,0.9128014842300557,0.8902229845626072,0.9581105169340464,0.0570409982174688,0.8913210720402442,0.056475260307357326,0.9469345278793149,0.12532241638007446,0.8602065520061454,0.9404639989200964,0.9294990723562152,0.9245283018867925,0.966131907308378,0.0392156862745098,0.9145769535827345,0.043316226580935306,0.9548996549272575,0.07996673037353205,0.9106106963323679,0.960800585467754,0.9294990723562152,0.9245283018867925,Llama-3.1-8B-Instruct
repetition,1122.0,583.0,539.0,0.5196078431372549,474.0,1057.0,0.9420677361853832,0.8794063079777366,35.0,0.031194295900178252,0.9399656946826758,509.0,0.4536541889483066,539.0,583.0,0.57436080494227,0.09441387739860811,0.32702007133692146,0.8549978107375363,0.8549978107375363,0.04409929722389513,0.8423005565862709,0.8936535162950258,0.9242424242424242,0.05525846702317291,0.8257362041345656,0.10067615603029971,0.9354597207272167,0.12499304901477408,0.846773908566529,0.9204494073524825,0.8552875695732839,0.8970840480274442,0.93048128342246,0.053475935828877004,0.846220605786979,0.08863515342546119,0.9375745372706623,0.11381014163444099,0.8661421380487512,0.9304082509550319,0.8794063079777366,0.9399656946826758,0.9420677361853832,0.031194295900178252,0.8734115225974461,0.073969531610306,0.9454109740481812,0.07906161560190425,0.9018327838784584,0.9434832944865754,0.8794063079777366,0.9399656946826758,Llama-3.1-8B-Instruct
Aggregated,1122.0,583.0,539.0,0.5196078431372549,496.42857142857144,1079.4285714285713,0.9620575502928445,0.9210177577524516,28.0,0.024955436720142603,0.9519725557461406,524.4285714285714,0.46740514387573207,539.0,583.0,0.57436080494227,0.0944138773986081,0.3270200713369214,0.8549978107375364,0.8549978107375364,0.04409929722389512,0.8407103100980653,0.8002940455770645,0.9234784823020117,0.10376878023936849,0.8260538343259622,0.09890835504414082,0.931395355664663,0.2069455876513741,0.758426408231345,0.9083074224120224,0.8974291015107344,0.921342808135261,0.9507257448433919,0.04087089381207028,0.885983618742631,0.06682319151877442,0.9497775597757266,0.0919818931354717,0.8899608979648977,0.9411855169639658,0.9210177577524516,0.9519725557461406,0.9620575502928445,0.024955436720142603,0.911062617183936,0.05257662423885873,0.95819185589425,0.05754555331151047,0.9298083389476934,0.9598231279427234,0.9210177577524516,0.9519725557461406,Llama-3.1-8B-Instruct
