[
  {
    "technique":"Evidence-based Persuasion",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":496.0,
    "final_pos_appeal_numerator":1079.0,
    "final_pos_appeal_accuracy":0.9616755793,
    "pos_flip_rate":0.9202226345,
    "final_neg_appeal_numerator":15.0,
    "final_neg_appeal_accuracy":0.013368984,
    "neg_flip_rate":0.974271012,
    "final_correct_count_global":511.0,
    "final_correct_accuracy_global":0.4554367201,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8441558442,
    "turn_1_neg_flip_rate":0.8319039451,
    "turn_1_pos_acc":0.9251336898,
    "turn_1_neg_acc":0.0873440285,
    "turn_1_conf_answer_pos":0.8276872833,
    "turn_1_conf_target_pos":0.0997767067,
    "turn_1_conf_selected_pos":0.9292557584,
    "turn_1_conf_answer_neg":0.1781781535,
    "turn_1_conf_target_neg":0.790190668,
    "turn_1_conf_selected_neg":0.9159616385,
    "turn_2_pos_flip_rate":0.9016697588,
    "turn_2_neg_flip_rate":0.9433962264,
    "turn_2_pos_acc":0.9527629234,
    "turn_2_neg_acc":0.0294117647,
    "turn_2_conf_answer_pos":0.8874530347,
    "turn_2_conf_target_pos":0.0684884958,
    "turn_2_conf_selected_pos":0.9447582243,
    "turn_2_conf_answer_neg":0.0708864211,
    "turn_2_conf_target_neg":0.9130540165,
    "turn_2_conf_selected_neg":0.9419179014,
    "turn_3_pos_flip_rate":0.9202226345,
    "turn_3_neg_flip_rate":0.974271012,
    "turn_3_pos_acc":0.9616755793,
    "turn_3_neg_acc":0.013368984,
    "turn_3_conf_answer_pos":0.9080784892,
    "turn_3_conf_target_pos":0.0577127846,
    "turn_3_conf_selected_pos":0.9581229642,
    "turn_3_conf_answer_neg":0.0377320528,
    "turn_3_conf_target_neg":0.9502787362,
    "turn_3_conf_selected_neg":0.9634649486,
    "final_pos_flip_rate":0.9202226345,
    "final_neg_flip_rate":0.974271012,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"Logical Appeal",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":503.0,
    "final_pos_appeal_numerator":1086.0,
    "final_pos_appeal_accuracy":0.9679144385,
    "pos_flip_rate":0.9332096475,
    "final_neg_appeal_numerator":16.0,
    "final_neg_appeal_accuracy":0.0142602496,
    "neg_flip_rate":0.9725557461,
    "final_correct_count_global":519.0,
    "final_correct_accuracy_global":0.4625668449,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8552875696,
    "turn_1_neg_flip_rate":0.8524871355,
    "turn_1_pos_acc":0.9304812834,
    "turn_1_neg_acc":0.0766488414,
    "turn_1_conf_answer_pos":0.8335156991,
    "turn_1_conf_target_pos":0.0947226206,
    "turn_1_conf_selected_pos":0.9365028098,
    "turn_1_conf_answer_neg":0.1612905426,
    "turn_1_conf_target_neg":0.8067308308,
    "turn_1_conf_selected_neg":0.9105182468,
    "turn_2_pos_flip_rate":0.8942486085,
    "turn_2_neg_flip_rate":0.9433962264,
    "turn_2_pos_acc":0.949197861,
    "turn_2_neg_acc":0.0294117647,
    "turn_2_conf_answer_pos":0.8898500087,
    "turn_2_conf_target_pos":0.065429445,
    "turn_2_conf_selected_pos":0.9565219039,
    "turn_2_conf_answer_neg":0.0700759889,
    "turn_2_conf_target_neg":0.9147363417,
    "turn_2_conf_selected_neg":0.9521798312,
    "turn_3_pos_flip_rate":0.9332096475,
    "turn_3_neg_flip_rate":0.9725557461,
    "turn_3_pos_acc":0.9679144385,
    "turn_3_neg_acc":0.0142602496,
    "turn_3_conf_answer_pos":0.9212314822,
    "turn_3_conf_target_pos":0.0485366969,
    "turn_3_conf_selected_pos":0.9609037969,
    "turn_3_conf_answer_neg":0.0383862868,
    "turn_3_conf_target_neg":0.9509007312,
    "turn_3_conf_selected_neg":0.9724322505,
    "final_pos_flip_rate":0.9332096475,
    "final_neg_flip_rate":0.9725557461,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"Expert Endorsement",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":499.0,
    "final_pos_appeal_numerator":1082.0,
    "final_pos_appeal_accuracy":0.9643493761,
    "pos_flip_rate":0.9257884972,
    "final_neg_appeal_numerator":30.0,
    "final_neg_appeal_accuracy":0.0267379679,
    "neg_flip_rate":0.948542024,
    "final_correct_count_global":529.0,
    "final_correct_accuracy_global":0.4714795009,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8423005566,
    "turn_1_neg_flip_rate":0.7993138937,
    "turn_1_pos_acc":0.9242424242,
    "turn_1_neg_acc":0.1042780749,
    "turn_1_conf_answer_pos":0.8321453184,
    "turn_1_conf_target_pos":0.0953706257,
    "turn_1_conf_selected_pos":0.9347364318,
    "turn_1_conf_answer_neg":0.2020503546,
    "turn_1_conf_target_neg":0.7646662532,
    "turn_1_conf_selected_neg":0.9027146836,
    "turn_2_pos_flip_rate":0.8961038961,
    "turn_2_neg_flip_rate":0.9279588336,
    "turn_2_pos_acc":0.9500891266,
    "turn_2_neg_acc":0.0374331551,
    "turn_2_conf_answer_pos":0.8880050823,
    "turn_2_conf_target_pos":0.0691096488,
    "turn_2_conf_selected_pos":0.9515559697,
    "turn_2_conf_answer_neg":0.0846967537,
    "turn_2_conf_target_neg":0.8935233425,
    "turn_2_conf_selected_neg":0.9395952946,
    "turn_3_pos_flip_rate":0.9257884972,
    "turn_3_neg_flip_rate":0.948542024,
    "turn_3_pos_acc":0.9643493761,
    "turn_3_neg_acc":0.0267379679,
    "turn_3_conf_answer_pos":0.9168073758,
    "turn_3_conf_target_pos":0.0521025361,
    "turn_3_conf_selected_pos":0.960393656,
    "turn_3_conf_answer_neg":0.0566284776,
    "turn_3_conf_target_neg":0.9292434659,
    "turn_3_conf_selected_neg":0.9562756186,
    "final_pos_flip_rate":0.9257884972,
    "final_neg_flip_rate":0.948542024,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"Authority Endorsement",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":498.0,
    "final_pos_appeal_numerator":1081.0,
    "final_pos_appeal_accuracy":0.9634581105,
    "pos_flip_rate":0.9239332096,
    "final_neg_appeal_numerator":22.0,
    "final_neg_appeal_accuracy":0.0196078431,
    "neg_flip_rate":0.9622641509,
    "final_correct_count_global":520.0,
    "final_correct_accuracy_global":0.4634581105,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8423005566,
    "turn_1_neg_flip_rate":0.8404802744,
    "turn_1_pos_acc":0.9242424242,
    "turn_1_neg_acc":0.0828877005,
    "turn_1_conf_answer_pos":0.8378437024,
    "turn_1_conf_target_pos":0.0962835248,
    "turn_1_conf_selected_pos":0.9361418708,
    "turn_1_conf_answer_neg":0.1769694217,
    "turn_1_conf_target_neg":0.790725328,
    "turn_1_conf_selected_neg":0.9124934773,
    "turn_2_pos_flip_rate":0.9146567718,
    "turn_2_neg_flip_rate":0.9399656947,
    "turn_2_pos_acc":0.9590017825,
    "turn_2_neg_acc":0.0311942959,
    "turn_2_conf_answer_pos":0.8989681244,
    "turn_2_conf_target_pos":0.0586794451,
    "turn_2_conf_selected_pos":0.9540200661,
    "turn_2_conf_answer_neg":0.0742918838,
    "turn_2_conf_target_neg":0.906172911,
    "turn_2_conf_selected_neg":0.9448724853,
    "turn_3_pos_flip_rate":0.9239332096,
    "turn_3_neg_flip_rate":0.9622641509,
    "turn_3_pos_acc":0.9634581105,
    "turn_3_neg_acc":0.0196078431,
    "turn_3_conf_answer_pos":0.9206134232,
    "turn_3_conf_target_pos":0.0485701664,
    "turn_3_conf_selected_pos":0.9651035208,
    "turn_3_conf_answer_neg":0.048213548,
    "turn_3_conf_target_neg":0.939500361,
    "turn_3_conf_selected_neg":0.9622963592,
    "final_pos_flip_rate":0.9239332096,
    "final_neg_flip_rate":0.9622641509,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"Positive Emotion Appeal",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":504.0,
    "final_pos_appeal_numerator":1087.0,
    "final_pos_appeal_accuracy":0.9688057041,
    "pos_flip_rate":0.9350649351,
    "final_neg_appeal_numerator":34.0,
    "final_neg_appeal_accuracy":0.0303030303,
    "neg_flip_rate":0.9416809605,
    "final_correct_count_global":538.0,
    "final_correct_accuracy_global":0.4795008913,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8311688312,
    "turn_1_neg_flip_rate":0.7084048027,
    "turn_1_pos_acc":0.9188948307,
    "turn_1_neg_acc":0.1515151515,
    "turn_1_conf_answer_pos":0.81090818,
    "turn_1_conf_target_pos":0.1050499739,
    "turn_1_conf_selected_pos":0.9216631586,
    "turn_1_conf_answer_neg":0.2857147363,
    "turn_1_conf_target_neg":0.6713693658,
    "turn_1_conf_selected_neg":0.8988997963,
    "turn_2_pos_flip_rate":0.9072356215,
    "turn_2_neg_flip_rate":0.9073756432,
    "turn_2_pos_acc":0.9554367201,
    "turn_2_neg_acc":0.0481283422,
    "turn_2_conf_answer_pos":0.9000674033,
    "turn_2_conf_target_pos":0.0609448922,
    "turn_2_conf_selected_pos":0.9570776893,
    "turn_2_conf_answer_neg":0.1047896464,
    "turn_2_conf_target_neg":0.875890984,
    "turn_2_conf_selected_neg":0.9388608564,
    "turn_3_pos_flip_rate":0.9350649351,
    "turn_3_neg_flip_rate":0.9416809605,
    "turn_3_pos_acc":0.9688057041,
    "turn_3_neg_acc":0.0303030303,
    "turn_3_conf_answer_pos":0.9227190737,
    "turn_3_conf_target_pos":0.0438284275,
    "turn_3_conf_selected_pos":0.9625084243,
    "turn_3_conf_answer_neg":0.0628301619,
    "turn_3_conf_target_neg":0.9262915982,
    "turn_3_conf_selected_neg":0.9600088387,
    "final_pos_flip_rate":0.9350649351,
    "final_neg_flip_rate":0.9416809605,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"Negative Emotion Appeal",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":501.0,
    "final_pos_appeal_numerator":1084.0,
    "final_pos_appeal_accuracy":0.9661319073,
    "pos_flip_rate":0.9294990724,
    "final_neg_appeal_numerator":44.0,
    "final_neg_appeal_accuracy":0.0392156863,
    "neg_flip_rate":0.9245283019,
    "final_correct_count_global":545.0,
    "final_correct_accuracy_global":0.4857397504,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.827458256,
    "turn_1_neg_flip_rate":0.6758147513,
    "turn_1_pos_acc":0.9171122995,
    "turn_1_neg_acc":0.1684491979,
    "turn_1_conf_answer_pos":0.8145404529,
    "turn_1_conf_target_pos":0.1004788776,
    "turn_1_conf_selected_pos":0.9260077394,
    "turn_1_conf_answer_neg":0.3194228559,
    "turn_1_conf_target_neg":0.6385285032,
    "turn_1_conf_selected_neg":0.8971147071,
    "turn_2_pos_flip_rate":0.9128014842,
    "turn_2_neg_flip_rate":0.8902229846,
    "turn_2_pos_acc":0.9581105169,
    "turn_2_neg_acc":0.0570409982,
    "turn_2_conf_answer_pos":0.891321072,
    "turn_2_conf_target_pos":0.0564752603,
    "turn_2_conf_selected_pos":0.9469345279,
    "turn_2_conf_answer_neg":0.1253224164,
    "turn_2_conf_target_neg":0.860206552,
    "turn_2_conf_selected_neg":0.9404639989,
    "turn_3_pos_flip_rate":0.9294990724,
    "turn_3_neg_flip_rate":0.9245283019,
    "turn_3_pos_acc":0.9661319073,
    "turn_3_neg_acc":0.0392156863,
    "turn_3_conf_answer_pos":0.9145769536,
    "turn_3_conf_target_pos":0.0433162266,
    "turn_3_conf_selected_pos":0.9548996549,
    "turn_3_conf_answer_neg":0.0799667304,
    "turn_3_conf_target_neg":0.9106106963,
    "turn_3_conf_selected_neg":0.9608005855,
    "final_pos_flip_rate":0.9294990724,
    "final_neg_flip_rate":0.9245283019,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"repetition",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":474.0,
    "final_pos_appeal_numerator":1057.0,
    "final_pos_appeal_accuracy":0.9420677362,
    "pos_flip_rate":0.879406308,
    "final_neg_appeal_numerator":35.0,
    "final_neg_appeal_accuracy":0.0311942959,
    "neg_flip_rate":0.9399656947,
    "final_correct_count_global":509.0,
    "final_correct_accuracy_global":0.4536541889,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8423005566,
    "turn_1_neg_flip_rate":0.8936535163,
    "turn_1_pos_acc":0.9242424242,
    "turn_1_neg_acc":0.055258467,
    "turn_1_conf_answer_pos":0.8257362041,
    "turn_1_conf_target_pos":0.100676156,
    "turn_1_conf_selected_pos":0.9354597207,
    "turn_1_conf_answer_neg":0.124993049,
    "turn_1_conf_target_neg":0.8467739086,
    "turn_1_conf_selected_neg":0.9204494074,
    "turn_2_pos_flip_rate":0.8552875696,
    "turn_2_neg_flip_rate":0.897084048,
    "turn_2_pos_acc":0.9304812834,
    "turn_2_neg_acc":0.0534759358,
    "turn_2_conf_answer_pos":0.8462206058,
    "turn_2_conf_target_pos":0.0886351534,
    "turn_2_conf_selected_pos":0.9375745373,
    "turn_2_conf_answer_neg":0.1138101416,
    "turn_2_conf_target_neg":0.866142138,
    "turn_2_conf_selected_neg":0.930408251,
    "turn_3_pos_flip_rate":0.879406308,
    "turn_3_neg_flip_rate":0.9399656947,
    "turn_3_pos_acc":0.9420677362,
    "turn_3_neg_acc":0.0311942959,
    "turn_3_conf_answer_pos":0.8734115226,
    "turn_3_conf_target_pos":0.0739695316,
    "turn_3_conf_selected_pos":0.945410974,
    "turn_3_conf_answer_neg":0.0790616156,
    "turn_3_conf_target_neg":0.9018327839,
    "turn_3_conf_selected_neg":0.9434832945,
    "final_pos_flip_rate":0.879406308,
    "final_neg_flip_rate":0.9399656947,
    "model_name":"Llama-3.1-8B-Instruct"
  },
  {
    "technique":"Aggregated",
    "total_samples":1122.0,
    "count_initially_correct":583.0,
    "count_initially_incorrect":539.0,
    "initial_accuracy":0.5196078431,
    "final_pos_appeal_incorrect_to_correct_count":496.4285714286,
    "final_pos_appeal_numerator":1079.4285714286,
    "final_pos_appeal_accuracy":0.9620575503,
    "pos_flip_rate":0.9210177578,
    "final_neg_appeal_numerator":28.0,
    "final_neg_appeal_accuracy":0.0249554367,
    "neg_flip_rate":0.9519725557,
    "final_correct_count_global":524.4285714286,
    "final_correct_accuracy_global":0.4674051439,
    "pos_subset_count":539.0,
    "neg_subset_count":583.0,
    "turn_0_conf_selected_pos":0.5743608049,
    "turn_0_conf_answer_pos":0.0944138774,
    "turn_0_conf_target_pos":0.3270200713,
    "turn_0_conf_selected_neg":0.8549978107,
    "turn_0_conf_answer_neg":0.8549978107,
    "turn_0_conf_target_neg":0.0440992972,
    "turn_1_pos_flip_rate":0.8407103101,
    "turn_1_neg_flip_rate":0.8002940456,
    "turn_1_pos_acc":0.9234784823,
    "turn_1_neg_acc":0.1037687802,
    "turn_1_conf_answer_pos":0.8260538343,
    "turn_1_conf_target_pos":0.098908355,
    "turn_1_conf_selected_pos":0.9313953557,
    "turn_1_conf_answer_neg":0.2069455877,
    "turn_1_conf_target_neg":0.7584264082,
    "turn_1_conf_selected_neg":0.9083074224,
    "turn_2_pos_flip_rate":0.8974291015,
    "turn_2_neg_flip_rate":0.9213428081,
    "turn_2_pos_acc":0.9507257448,
    "turn_2_neg_acc":0.0408708938,
    "turn_2_conf_answer_pos":0.8859836187,
    "turn_2_conf_target_pos":0.0668231915,
    "turn_2_conf_selected_pos":0.9497775598,
    "turn_2_conf_answer_neg":0.0919818931,
    "turn_2_conf_target_neg":0.889960898,
    "turn_2_conf_selected_neg":0.941185517,
    "turn_3_pos_flip_rate":0.9210177578,
    "turn_3_neg_flip_rate":0.9519725557,
    "turn_3_pos_acc":0.9620575503,
    "turn_3_neg_acc":0.0249554367,
    "turn_3_conf_answer_pos":0.9110626172,
    "turn_3_conf_target_pos":0.0525766242,
    "turn_3_conf_selected_pos":0.9581918559,
    "turn_3_conf_answer_neg":0.0575455533,
    "turn_3_conf_target_neg":0.9298083389,
    "turn_3_conf_selected_neg":0.9598231279,
    "final_pos_flip_rate":0.9210177578,
    "final_neg_flip_rate":0.9519725557,
    "model_name":"Llama-3.1-8B-Instruct"
  }
]